---
title: "DebGPT+text-generation-webuiã§VRAMå°‘ãªã„GPUã§ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆAIã«å…¥é–€ã—ã¦ã¿ã‚‹æ–¹æ³•(2024å¹´2æœˆæ™‚ç‚¹)"
emoji: "ğŸª”"
type: "tech"
topics: ["Debian", "Linux"]
published: true
---


æœ¬è¨˜äº‹ã¯DebGPTã‚’ãã£ã‹ã‘ã«ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆAIã‚’è©¦ã—ã¦ã¿ã‚ˆã†ã¨æ€ã£ãŸäººã®ãŸã‚ã®è¨˜äº‹ã§ã™ã€‚

[ã²ã¨ã‚Šã—ãšã‹ã«ã€‚- DebGPT+text-generation-webuiã§ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆAIã«å…¥é–€ã—ã¦ã¿ã‚‹æ–¹æ³•(2024å¹´2æœˆæ™‚ç‚¹)](https://kenhys.hatenablog.jp/entry/2024/02/19/203943)ã¨ã®ã‚¯ãƒ­ã‚¹ãƒã‚¹ãƒˆè¨˜äº‹ã§ã™ã€‚

[2024/02/17(åœŸ)ã®Debianå‹‰å¼·ä¼š(ã‚ªãƒ³ãƒ©ã‚¤ãƒ³é–‹å‚¬)](https://debianjp.connpass.com/event/309003/)ã®å†…å®¹ã‚’ãã£ã‹ã‘ã«ã“ã®è¨˜äº‹ã¯åŸ·ç­†ã•ã‚Œã¾ã—ãŸã€‚

# ã¯ã˜ã‚ã«

Debianå‹‰å¼·ä¼šã§ã€é‡é¦–ã•ã‚“ã«ã‚ˆã‚Šã€ŒRAGã¨LLM ãã—ã¦DebGPTã€ã¨ã„ã†ã‚»ãƒŸãƒŠãƒ¼ãŒã‚ã‚Šã¾ã—ãŸã€‚

> DebGPTã¨ã„ã†ãƒ„ãƒ¼ãƒ«ãŒå…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸»ã«Debianã®ãƒªã‚½ãƒ¼ã‚¹(BTS, builddç­‰)ã‚’å‚ç…§ã—ã€OpenAI APIã‚’çµŒç”±ã—ãŸChatGPTã«ã‚ˆã‚‹è¦ç´„ã€èª¬æ˜ã¨ã„ã£ãŸã“ã¨ãŒå¯èƒ½ã§ã™ã€‚ã¾ãŸã€Mistral AIç¤¾ã®å…¬é–‹ã—ã¦ã„ã‚‹ãƒ­ãƒ¼ã‚«ãƒ«å‘ã‘LLMã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿéš›ã«ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ä½œã•ã›ã¦ã¿ã‚‹ã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚„ã€ å†…éƒ¨ã®æŒ™å‹•ã®è§£èª¬ã€ãã—ã¦text-generation-webuiã¨ã„ã†ãƒ„ãƒ¼ãƒ«ã‚’ä»‹ã—ã¦ä»–ã®LLMã‚’ä½¿ã†æ‰‹é †ãªã©ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

å½“æ—¥ã®è³‡æ–™ã¯ [RAGã¨LLM ãã—ã¦DebGPT](https://t.co/MpIALwfqf5)ã¨ã—ã¦å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

ã„ã‚ã‚†ã‚‹ç”ŸæˆAIç³»ã¯VRAMã‚’å¤§é‡ã«ç©ã‚“ã GPUã‚’ä½¿ã£ã¦ã„ã‚‹äººã®ãŸã‚ã®ã‚‚ã®ã¨ã„ã†å°è±¡ãŒå¼·ã‹ã£ãŸã®ã§ã€
èˆˆå‘³ãŒã²ã‹ã‚Œã‚‹ã‚‚ã®ã®ã€ã“ã‚Œã¾ã§æ‰‹ã‚’ã ã™ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚

ç¾åœ¨åˆ©ç”¨ã—ã¦ã„ã‚‹PCã§ã¯GTX 1660ãªã®ã§æ­è¼‰ã—ã¦ã„ã‚‹VRAMã¯6GBã¨ã€PCã§ã‚²ãƒ¼ãƒ ã‚’ã—ãªã„ç”¨é€”ã§ã¯ååˆ†ã§ã™ãŒã€ç”ŸæˆAIã‚’æ´»ç”¨ã™ã‚‹ã«ã¯ä¸å‘ãã§ã™ã€‚

ã‚„ã‚ŒGTX3090ãŒã„ã„ã¨ã‹æœ­æŸã§æ®´ã‚‹ã“ã¨ã§è§£æ±ºã§ãã‚‹ä¸–ç•Œã§ã¯ã‚ã‚Šã¾ã™ãŒã€ãã‚‚ãã‚‚æ‰‹æŒã¡ã®GPUã‚’åˆ·æ–°ã—ã‚ˆã†ã«ã‚‚ã€
é›»æºã®éƒ½åˆã§è£œåŠ©é›»æº8pin x 1ã®åˆ¶ç´„ãŒã‚ã‚‹ã®ã§ã€ãã‚Œã»ã©å¼·åŠ›ãªGPUã¯ãã‚‚ãã‚‚ç©ã‚ã¾ã›ã‚“ã€‚
(è£œåŠ©é›»æº8pin x 1ã ã¨Radeonã ã¨RX7600ã‚ãŸã‚Šã¾ã§ã€NVIDIAãªã‚‰GTX 3070 or GTX4060ã‚ãŸã‚Šã¾ã§ã®ã¯ãšã€‚)

ãã‚Œã§ã‚‚ã€æœ€è¿‘ã¯æ··åˆãƒ¡ãƒ¢ãƒªæ–¹å¼ã«ã‚ˆã‚Šã€æ­è¼‰VRAMãŒã™ããªãã¦ã‚‚å‹•ä½œã•ã›ã‚‰ã‚Œã‚‹ã¨ã„ã†è©±ã‚’èã„ãŸã®ã§è©¦ã—ã¦ã¿ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚

# ç’°å¢ƒæ§‹ç¯‰ã‚’ã™ã‚‹

æœ¬è¨˜äº‹ã§ã¯ã€Debian sid with GTX 1660ã§ç’°å¢ƒæ§‹ç¯‰ã™ã‚‹å‰æã¨ã—ã¾ã™ã€‚
ä»–ã®ç’°å¢ƒã§ã¯é©å®œèª­ã¿æ›¿ãˆã¦ãã ã•ã„ã€‚

* nvidia-driverã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (525.147.05-7)
* text-generation-webuiã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
* LLMã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
* DebGPTã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹

## nvidia-driverã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

æ®‹å¿µãªã“ã¨ã«ã€GPUã‚’ãƒ•ãƒ«ã«æ´»ã‹ã™ã«ã¯ã€è‡ªç”±ãªnouveauãƒ‰ãƒ©ã‚¤ãƒã§ã¯ãªããƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãªnvidia-driverã‚’ä½¿ã£ãŸã»ã†ãŒéƒ½åˆãŒã‚ˆã•ãã†ãªã®ã§ã€
nvidia-driverã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãŠãã¾ã™ã€‚

```
$ sudo apt install -y nvidia-driver
```

ã™ã‚‹ã¨ã€nouveauãƒ‰ãƒ©ã‚¤ãƒã‚’åˆ©ç”¨ã—ãªã„ã‚ˆã†ã«è¨­å®šãŒãªã•ã‚Œã¾ã™ã€‚

```
$ cat /etc/modprobe.d/nvidia-blacklists-nouveau.conf
# You need to run "update-initramfs -u" after editing this file.

# see #580894
blacklist nouveau
```

å†èµ·å‹•ã™ã‚‹ã¨nvidia-driverãŒä½¿ã‚ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã¯ãšã§ã™ã€‚

nouveauãƒ‰ãƒ©ã‚¤ãƒã¨nvidia driverã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã¤ã„ã¦ã¯ã„ãã¤ã‹å‚è€ƒè³‡æ–™ãŒã‚ã‚Šã¾ã™ã€‚
ã¡ã‚‡ã£ã¨å¤ã„ã¨ã¯ã„ãˆã¾ã ã¾ã çµæ§‹ãªå·®ã‚’ã¤ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚

* [The Open-Source NVIDIA/Nouveau vs. NVIDIA Linux Driver At The End Of 2019 - Poor But A Lot Of Hope](https://www.phoronix.com/review/nvidia-nouveau-2019/2)
* [Nouveau 2021 Performance on Kepler vs. NVIDIA Linux](https://openbenchmarking.org/result/2106300-IB-NOUVEAU2060)

## text-generation-webuiã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆAIã‚’WebUIçµŒç”±ã§ç°¡å˜ã«åˆ©ç”¨ã™ã‚‹ãŸã‚ã«ã€text-generation-webuiã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’è¡Œã„ã¾ã™ã€‚

```bash
$ git clone https://github.com/oobabooga/text-generation-webui.git
$ cd text-generation-webui.git
$ ./start_linux.sh
```

é€”ä¸­ã§ç’°å¢ƒã«é–¢ã—ã¦èã‹ã‚Œã‚‹ã®ã§ã€é©å®œé¸æŠã—ã¾ã™ã€‚

```bash
What is your GPU?

A) NVIDIA
B) AMD (Linux/MacOS only. Requires ROCm SDK 5.6 on Linux)
C) Apple M Series
D) Intel Arc (IPEX)
N) None (I want to run models in CPU mode)

Input> A

Do you want to use CUDA 11.8 instead of 12.1? Only choose this option if your GPU is very old (Kepler or older).
For RTX and GTX series GPUs, say "N". If unsure, say "N".

Input (Y/N)> N
```

GTX1660ãªã®ã§Turingä¸–ä»£ã ã‹ã‚‰12.1ç³»ã®CUDAãŒåˆ©ç”¨ã§ãã‚‹ã¯ãšãªã®ã§ã€Nã‚’é¸æŠã—ã¾ã™ã€‚

ã“ã‚Œã§install_filesé…ä¸‹ã«å¿…è¦ãªãƒ©ãƒ³ã‚¿ã‚¤ãƒ ç­‰ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã™ã€‚

ã‚‚ã‚ã‚‚ã‚ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒçµ‚ã‚ã£ãŸã‚‰ã€å†åº¦æ¬¡ã®ã‚ˆã†ã«ã—ã¦./start_linux.shã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```
$ ./start_linux.sh --api --listen --api-port 5000
```

ã™ã‚‹ã¨ã€Web UIã¯ http://localhost:7860 ã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã€ç”ŸæˆAIã®APIã¯ http://localhost:5000/v1 ã¨ã—ã¦ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

## LLMã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

LLMã‚’å‹•ä½œã•ã›ã‚‹ãŸã‚ã«ã€ãƒ¢ãƒ‡ãƒ«ãŒãªã„ã¨ã©ã†ã—ã‚ˆã†ã‚‚ãªã„ã®ã§å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

* http://localhost:7860 ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹
* Modelã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹
* Download model or LoRAã«ã€ŒTheBloke/Mistral-7B-Instruct-v0.2-GGUFã€ã‚’å…¥åŠ›ã™ã‚‹
* File name (for GGUF models)ã«ã€Œmistral-7b-instruct-v0.2.Q5_K_M.ggufã€ã‚’å…¥åŠ›ã™ã‚‹
* Downloadã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹

ä¸Šè¨˜ã«ã‚ˆã‚Šã€å¿…è¦ãªGGUFãƒ•ã‚¡ã‚¤ãƒ«ãŒmodel/é…ä¸‹ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚

[mistral-7b-instruct-v0.2.Q5_K_M.gguf](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF] ã¯ã‚µã‚¤ã‚ºãŒå¤§ãã„ã‚‚ã®ã®ã€å“è³ªä½ä¸‹ãŒå°‘ãªã„ã¨ã„ã†ã“ã¨ã§
ãŠã™ã™ã‚ã¨ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

é€Ÿåº¦ã‚’ã¨ã‚‹ã‹ã€å“è³ªã‚’ã¨ã‚‹ã‹ã§ã„ãã¤ã‹ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚

ãƒ¢ãƒ‡ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ããŸã‚‰ã€ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
.ggufãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã™ã‚‹ã¨Model loaderã«llama.cppãŒé¸æŠã•ã‚Œã¾ã™ã€‚

Model loaderã«ã¯ã„ãã¤ã‹æŒ™å‹•ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã€‚

* n-gpu-layers: GPUã‚’æ´»ç”¨ã™ã‚‹ãªã‚‰ã“ã®å€¤ã‚’å¢—ã‚„ã—ã¾ã™ã€‚ãŸã ã—GTX1660(VRAM: 6GB)ã§ã¯9ãŒä¸Šé™ã®ã‚ˆã†ã§ã™ã€‚
* n_batch: ãƒãƒƒãƒå‡¦ç†ã™ã‚‹å˜ä½ã‚’å¢—ã‚„ã—ã¦é«˜é€ŸåŒ–ã™ã‚‹ãªã‚‰ã“ã®å€¤ã‚’å¢—ã‚„ã—ã¾ã™ã€‚ãŸã ã—ã€GTX1660ã§ã¯ãã‚Œã»ã©å¢—ã‚„ã›ãš530ã‚ãŸã‚ŠãŒä¸Šé™ã®ã‚ˆã†ã§ã™ã€‚
* tensorcores: tensor coreã‚’æ´»ç”¨ã™ã‚‹ãªã‚‰ãƒã‚§ãƒƒã‚¯ã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã€‚

Modelã®Loadãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚
ãƒ¡ãƒ¢ãƒªãŒè¶³ã‚Šã¦ã„ãªã‹ã£ãŸã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸é©åˆ‡ã ã¨ã‚ã£ã•ã‚Šä¾‹å¤–ã‚’åãã¾ã™ã€‚

å•é¡Œãªããƒ­ãƒ¼ãƒ‰ã§ããŸã‚‰ã€Chatã‚¿ãƒ–ã§who are you?ã¨ã‹å…¥åŠ›ã—ã¦ã¿ã‚‹ã¨ã€å¿œç­”ãŒè¿”ã£ã¦ãã‚‹ã¯ãšã§ã™ã€‚

## DebGPTã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹

ç”ŸæˆAIã‚’APIçµŒç”±ã§å©ã‘ã‚‹ã‚ˆã†ã«ãªã£ãŸã¯ãšãªã®ã§ã€æ¬¡ã¯DebGTPã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’è¡Œã„ã¾ã™ã€‚

DebGPTã¯ã¾ã trixieä»¥é™ã§ãªã„ã¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒãªã„ãŸã‚ã€DebGPTå‘ã‘ã®Pythonã®åˆ†é›¢ç’°å¢ƒã‚’ã‚ã‚‰ã‹ã˜ã‚ç”¨æ„ã—ãŸã†ãˆã§ã€ãƒªãƒã‚¸ãƒˆãƒªã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚
ã‚ã‚‰ã‹ã˜ã‚pyenvãŒåˆ©ç”¨ã§ãã‚‹å‰æã¨ã—ã¾ã™ã€‚

```bash
$ pyenv install 3.12.2
$ pyenv virtualenv 3.12.2 py312-debgpt
$ pyenv local py312-debgpt
```

```bash
$ git clone https://salsa.debian.org/deeplearning-team/debgpt.git
$ cd debgpt
$ pip3 install .
```

debgptã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸã‚‰ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

```bash
$ debgpt genconfig > $HOME/.debgpt/config.toml
```

æ¬¡ã«config.tomlã®openai_base_urlã‚’æ›¸ãæ›ãˆã¾ã™ã€‚ã“ã‚Œã¯å…ˆç¨‹ã® text-generation-webuiã‚’åˆ©ç”¨ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ã‹ã—ã¦ã„ã‚‹ç”ŸæˆAIã®APIã‚µãƒ¼ãƒãƒ¼ã‚’å‚ç…§ã™ã‚‹ãŸã‚ã®è¨­å®šã§ã™ã€‚

```
#openai_base_url = 'https://api.openai.com/v1'
openai_base_url = 'http://localhost:5000/v1'
```

## DebGPTã‚’ä½¿ã£ã¦ã¿ã‚‹


README.mdã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€ãƒ¡ãƒ¼ãƒªãƒ³ã‚°ãƒªã‚¹ãƒˆã®å†…å®¹ã‚’è¦ç´„ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```bash
$ debgpt -HQ --html 'https://lists.debian.org/debian-project/2023/12/msg00029.html' -A :summary
```

`-HQ`ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤ºã›ãšã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ã‘å–ã£ãŸã‚‰çµ‚äº†ã™ã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```bash
[20:14:52] OpenAIFrontend> Starting conversation 19d6f92e-51f9-427d-9955-8267380e3892                                         frontend.py:66
LLM[2]> Mo Zhou has created a new project repo for DebGPT, a Debian-specific LLM (Large Language Model),
at <https://salsa.debian.org/deeplearning-team/debgpt>.
The project does not require expensive hardware or training, and Zhou plans to wrap debian-specific prompts with an existing chatting LLM.
However, Zhou is uncertain about the performance of smaller LLMs in this case and their quantization to int8 or int4 for laptops.
The dependencies needed by the project are not complete in the Debian archive. Zhou invites interested people to discuss the project in the repo issues.
```


å…ƒã®HTMLã®å†…å®¹ãŒä»¥ä¸‹ã®é€šã‚Šãªã®ã§ã€æƒ…å ±æ¬ è½ã—ã¦ã„ã‚‹ã¨ã¯ã„ãˆã€ãã‚Œã£ã½ãè¦ç´„ã—ã¦ãã‚Œã‚‹ã¨ã¯ã„ãˆãã†ã§ã™ã€‚

```
On 12/30/23 21:40, Mo Zhou wrote:

> >   I am not
> >   able to develop DebGPT and confess I am not investing my time in
> >   learning to do it.  But can we attract the people who want to tinker in
> >   this direction?

> Debian funds should be able to cover the hardware requirement and training expenses even if they are slightly expensive. The more expensive thing is the time of domain experts. I can train such a model but clearly I do not have bandwidth for that.

No. I changed my mind.

I can actually quickly wrap some debian-specific prompts with an existing chatting LLM. This is easy and does not need expensive hardware (although it may still require 1~2 GPUs with 24GB memory for inference), nor any training procedure.
The project repo is created here https://salsa.debian.org/deeplearning-team/debgpt
I have enabled issues. And maybe people interested in this can redirect the detailed discussions to the repo issues.
I'm sure it is already possible to let LLM read the long policy document, or debhelper man pages for us, and provide some suggestions or patches. The things I'm uncertain is (1) how well a smaller LLM, like 7B or 13B ones can do compared to proprietary LLMs in this case; (2) how well a smaller LLM can be when it is quantized to int8 or even int4 for laptops.
Oh, BTW, the dependencies needed by the project are not complete in debian archive. 
```

# ã•ã„ã”ã«

æœ¬è¨˜äº‹ã¯ã€DebGPT+text-generation-webuiã§VRAMå°‘ãªã„GPUã§ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆAIã«å…¥é–€ã—ã¦ã¿ã‚‹æ–¹æ³•(2024å¹´2æœˆæ™‚ç‚¹)ã‚’ç´¹ä»‹ã—ã¾ã—ãŸã€‚

ã²ã¨ã¾ãšè‹±èªã§è©¦ã—ã¦ã¿ã¾ã—ãŸãŒã€æ¬¡ã¯æ—¥æœ¬èªã§å¿œç­”ã‚’è¿”ã›ã‚‹ã‚ˆã†ã«ã—ã¦ã¿ãŸã„ã¨ã“ã‚ã§ã™ã€‚


ã“ã®è¨˜äº‹ã¯Ultimate Hacking Keyboard v2ã§åŸ·ç­†ã—ã¾ã—ãŸã€‚
